# -*- coding: utf-8 -*-
"""3_玉川夏生.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_QzTyLK7-s69JlFQJEVGpbcLp2uk5nLM
"""

from google.colab import drive
drive.mount('/content/drive')

import os, sys
os.chdir('/content/drive/MyDrive/MU-Image-Speech-recognition/Face-Detection-in-Python-using-OpenCV-master')

!pwd

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import cv2 
import matplotlib.pyplot as plt
# %matplotlib inline

haar_cascade_face = cv2.CascadeClassifier('data/haarcascades/haarcascade_frontalface_alt2.xml')

def detect_faces(cascade, test_image, scaleFactor = 1.1, minNeighbors = 5):
    image_copy = test_image.copy()
    
    gray_image = cv2.cvtColor(image_copy, cv2.COLOR_BGR2GRAY)
    
    faces_rect = cascade.detectMultiScale(gray_image, scaleFactor=scaleFactor, minNeighbors=minNeighbors)

    print('Faces found: ', len(faces_rect))

    for (x, y, w, h) in faces_rect:
        cv2.rectangle(image_copy, (x, y), (x+w, y+h), (0, 255, 0), 2)
        
    return image_copy

def convertToRGB(image):
    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

from pylab import *

img = cv2.imread('/content/drive/MyDrive/MU-Image-Speech-recognition/PCV-master/Images/IMG_1507.jpg', cv2.IMREAD_UNCHANGED)

print('Original Dimensions : ',img.shape)

scale_percent = 20
width = int(img.shape[1] * scale_percent / 100)
height = int(img.shape[0] * scale_percent / 100)
dim = (width, height)

resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)

print('Resized Dimensions : ',resized.shape)
 
test_image = resized

faces = detect_faces(haar_cascade_face, test_image, scaleFactor=1.1, minNeighbors=3)

plt.imshow(convertToRGB(test_image))
show()

plt.imshow(convertToRGB(faces))

from pylab import *

img = cv2.imread('/content/drive/MyDrive/MU-Image-Speech-recognition/PCV-master/Images/IMG_2312.JPG', cv2.IMREAD_UNCHANGED)

print('Original Dimensions : ',img.shape)

scale_percent = 30
width = int(img.shape[1] * scale_percent / 100)
height = int(img.shape[0] * scale_percent / 100)
dim = (width, height)

resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)

print('Resized Dimensions : ',resized.shape)
 
test_image = resized

faces = detect_faces(haar_cascade_face, test_image, scaleFactor=1.1, minNeighbors=5)

plt.imshow(convertToRGB(test_image))
show()

plt.imshow(convertToRGB(faces))

from pylab import *

img = cv2.imread('/content/drive/MyDrive/MU-Image-Speech-recognition/PCV-master/Images/IMG_2323.JPG', cv2.IMREAD_UNCHANGED)

print('Original Dimensions : ',img.shape)

scale_percent = 150
width = int(img.shape[1] * scale_percent / 100)
height = int(img.shape[0] * scale_percent / 100)
dim = (width, height)

resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)

print('Resized Dimensions : ',resized.shape)
 
test_image = resized

faces = detect_faces(haar_cascade_face, test_image, scaleFactor=1.1, minNeighbors=7)

plt.imshow(convertToRGB(test_image))
show()

plt.imshow(convertToRGB(faces))

from pylab import *

img = cv2.imread('/content/drive/MyDrive/MU-Image-Speech-recognition/PCV-master/Images/IMG_3701.JPG', cv2.IMREAD_UNCHANGED)

print('Original Dimensions : ',img.shape)

scale_percent = 30
width = int(img.shape[1] * scale_percent / 100)
height = int(img.shape[0] * scale_percent / 100)
dim = (width, height)

resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)
rotate = cv2.rotate(resized, cv2.ROTATE_90_CLOCKWISE)

print('Resized Dimensions : ',rotate.shape)
 
test_image = rotate

faces = detect_faces(haar_cascade_face, test_image, scaleFactor=1.1, minNeighbors=5)

plt.imshow(convertToRGB(test_image))
show()

plt.imshow(convertToRGB(faces))

from pylab import *

img = cv2.imread('/content/drive/MyDrive/MU-Image-Speech-recognition/PCV-master/Images/IMG_5376.JPG', cv2.IMREAD_UNCHANGED)

print('Original Dimensions : ',img.shape)

scale_percent = 20
width = int(img.shape[1] * scale_percent / 100)
height = int(img.shape[0] * scale_percent / 100)
dim = (width, height)

resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)

print('Resized Dimensions : ',resized.shape)
 
test_image = resized

faces = detect_faces(haar_cascade_face, test_image, scaleFactor=1.1, minNeighbors=1)

plt.imshow(convertToRGB(test_image))
show()

plt.imshow(convertToRGB(faces))

from pylab import *

img = cv2.imread('/content/drive/MyDrive/MU-Image-Speech-recognition/PCV-master/Images/IMG_6673.PNG', cv2.IMREAD_UNCHANGED)

print('Original Dimensions : ',img.shape)

scale_percent = 150
width = int(img.shape[1] * scale_percent / 100)
height = int(img.shape[0] * scale_percent / 100)
dim = (width, height)

resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)

print('Resized Dimensions : ',resized.shape)
 
test_image = resized

faces = detect_faces(haar_cascade_face, test_image, scaleFactor=1.1, minNeighbors=100)

plt.imshow(convertToRGB(test_image))
show()

plt.imshow(convertToRGB(faces))